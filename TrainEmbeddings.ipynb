{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjdolan/HighResolutionSemanticClassification/blob/main/TrainEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSJhbxCew1Wa"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55y596OByfaF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urljoin\n",
        "from shapely.geometry import Polygon\n",
        "import numpy as np\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import zipfile\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import auth\n",
        "import os\n",
        "import rasterio\n",
        "import shutil\n",
        "from matplotlib import pyplot as plt\n",
        "from rasterio.plot import show\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ast import literal_eval\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "# !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "# !apt -qq update\n",
        "# !apt -qq install gcsfuse\n",
        "\n",
        "# !mkdir bucket_data\n",
        "# !gcsfuse --implicit-dirs atml_bucket bucket_data\n",
        "# headers = {}\n",
        "# payload = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HusYO0r5bb-h"
      },
      "outputs": [],
      "source": [
        "FIRST_RUN = False\n",
        "HAVE_FILES = True\n",
        "\n",
        "NEW_IMG_SIZE = 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRD5-scpyhBF"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ATML_Dataset_Largest.csv')\n",
        "df['bbox'] = df['bbox'].apply(lambda x: literal_eval(x))\n",
        "df['Class'] = df['Class'].apply(lambda x: literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCK-cH6-kZP3"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq67RtpdcU-p"
      },
      "outputs": [],
      "source": [
        "if not HAVE_FILES:\n",
        "  IMAGE_DIR = '/content/drive/MyDrive/ATMLData/atml_bucket/'\n",
        "  fileNames = [x.split('/')[-1].lower() for x in glob(IMAGE_DIR + '*.tif')]\n",
        "\n",
        "  !rm -r /content/drive/MyDrive/NAIP_Lower_Res_3000_v3\n",
        "  !mkdir /content/drive/MyDrive/NAIP_Lower_Res_3000_v3\n",
        "  for idx in tqdm(range(len(fileNames)), position=0, leave=True):\n",
        "    with rasterio.open(IMAGE_DIR + fileNames[idx]) as img:\n",
        "      img_new = img.read(out_shape=(img.count, int(3000), int(3000)),\n",
        "                          resampling=Resampling.bilinear)\n",
        "      img_new = img_new[0:3,:,:]\n",
        "      img_new = np.transpose(img_new, (1,2,0))\n",
        "            \n",
        "\n",
        "      cv2.imwrite('/content/drive/MyDrive/NAIP_Lower_Res_3000_v3/' + fileNames[idx][:-4] + '.png', img_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-43ebh80bgDe"
      },
      "outputs": [],
      "source": [
        "if FIRST_RUN:\n",
        "  def correct_bbox(fileName, bbox, new_size):\n",
        "    new_bbox = []\n",
        "    try:\n",
        "      with rasterio.open('/content/drive/MyDrive/ATMLData/atml_bucket/' + fileName.lower() + '.tif') as img:\n",
        "        for box in bbox:\n",
        "          new_box = []\n",
        "          y_old = img.shape[0]\n",
        "          x_old = img.shape[1]\n",
        "\n",
        "          for i in range(4):\n",
        "            old = None\n",
        "            if i % 2 == 0:\n",
        "              old = x_old\n",
        "            else:\n",
        "              old = y_old\n",
        "            new_val = int((float(box[i]) / float(old)) * new_size)\n",
        "            if new_val < 0:\n",
        "              new_val = 0\n",
        "            elif new_val > new_size:\n",
        "              new_val = new_size\n",
        "            new_box.append(new_val)\n",
        "\n",
        "\n",
        "          new_bbox.append(new_box)\n",
        "    except:\n",
        "      print('Failed on file ' + str(fileName.lower()))\n",
        "\n",
        "    return new_bbox\n",
        "\n",
        "  tqdm.pandas()\n",
        "  df['bbox'] = df[['fileName', 'bbox']].progress_apply(lambda x: correct_bbox(x.fileName, x.bbox, NEW_IMG_SIZE), axis=1)\n",
        "  df.to_csv('/content/drive/MyDrive/ATML_Dataset_' + str(NEW_IMG_SIZE)  + '.csv')\n",
        "\n",
        "  import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aezDtmvySNW0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ATML_Dataset_' + str(NEW_IMG_SIZE) + '.csv')\n",
        "df['bbox'] = df['bbox'].apply(lambda x: literal_eval(x))\n",
        "df['Class'] = df['Class'].apply(lambda x: literal_eval(x))\n",
        "encodings = {'airport':0, 'stadium':1, 'power_plant':2}\n",
        "\n",
        "df['Label'] = df['Class'].apply(lambda x: [encodings[y] for y in x])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame(columns=df.columns)\n",
        "idx = 0\n",
        "for index, row in tqdm(df.iterrows(), position=0, leave=True):\n",
        "  if len(row.bbox) > 0:\n",
        "    for i in range(len(row.bbox)):\n",
        "      new_df.at[idx, 'fileName'] = row.fileName + '_' + str(i)\n",
        "      new_df.at[idx, 'bbox'] = row.bbox[i]\n",
        "      new_df.at[idx, 'Class'] = row.Class[i]\n",
        "      new_df.at[idx, 'Label'] = row.Label[i]\n",
        "      idx += 1\n",
        "df = new_df"
      ],
      "metadata": {
        "id": "vALSqYf_75tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USCfbCcRy9QD"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aFMtzEg5dFBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnVo1vAS1Gg0"
      },
      "source": [
        "Import PyTorch libraries for building vision autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWO3hpXx1GBF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q8ATgs64ML8"
      },
      "outputs": [],
      "source": [
        "with rasterio.open(IMAGE_DIR + fileNames[50]) as img:\n",
        "  img = img.read(window=((0, 256), (0, 256))) / 255\n",
        "  print(np.max(img))\n",
        "  show(img[0:3,0:256,0:256])\n",
        "  print(type(img[0,0,0]))\n",
        "  np.save('/content/test',img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsHDhXU74To-"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtbsextqNdfu"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/ATMLDataPatches/' + fileNames[0][:-4] + '_' + str(0) + '.png')\n",
        "np.transpose(img, (2,0,1)).shape\n",
        "print(type(img[0,0,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEdo-595uKvg"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgARTj7DuRqX"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE=256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnXO-D0rlRp0"
      },
      "outputs": [],
      "source": [
        "from rasterio.enums import Resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uwPRMF7lyDK"
      },
      "outputs": [],
      "source": [
        "a = 6540\n",
        "b = 2000 / a\n",
        "print(int(a * b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osHoo4uUmzQI"
      },
      "outputs": [],
      "source": [
        "idx = 200\n",
        "with rasterio.open(IMAGE_DIR + fileNames[idx]) as img:\n",
        "      img_new = img.read()\n",
        "      show(img_new[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jcK7jsP9-rJ"
      },
      "outputs": [],
      "source": [
        "IMAGE_DIR = '/content/drive/MyDrive/NAIP_Lower_Res_' + str(NEW_IMG_SIZE) + '_v3/'\n",
        "fileNames = [x.split('/')[-1].lower() for x in glob(IMAGE_DIR + '*.png')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzRjCrMo-iUK"
      },
      "outputs": [],
      "source": [
        "print(len(fileNames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjBzNGlf4HKU"
      },
      "outputs": [],
      "source": [
        "dims = {0:[0,0], 1:[0,0], 2:[0,0]}\n",
        "dim_counts = {0:0,1:0,2:0}\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0], position=0, leave=True):\n",
        "  dims[row.Label][0] += (row.bbox[2] - row.bbox[0])\n",
        "  dims[row.Label][1] += (row.bbox[3] - row.bbox[1])\n",
        "  if (row.bbox[2] - row.bbox[0]) < 0:\n",
        "    print('Broken x')\n",
        "  if (row.bbox[3] - row.bbox[1]) < 0:\n",
        "    print('Broken y')\n",
        "  dim_counts[row.Label] += 1\n",
        "for k in dims.keys():\n",
        "  print('Label ' + str(k) + ' dims:')\n",
        "  print('Average x size = ' + str(dims[k][0]/dim_counts[k]))\n",
        "  print('Average y size = ' + str(dims[k][1]/dim_counts[k]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_SIZES = {0:512,1:256,2:256}\n",
        "PADDING = 24"
      ],
      "metadata": {
        "id": "ccB2LfcH_JeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "VOfeXnTRHIfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATCHES = True"
      ],
      "metadata": {
        "id": "WOGsazqbN-h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = df.iloc[1000]\n",
        "print(row)\n",
        "img = cv2.imread(IMAGE_DIR + row.fileName.lower()[:-2] + '.png')\n",
        "center_x = int((row.bbox[0] + row.bbox[2]) / 2)\n",
        "center_y = int((row.bbox[1] + row.bbox[3]) / 2)\n",
        "img = img[center_y - (PATCH_SIZES[row.Label] + PADDING)//2:center_y + (PATCH_SIZES[row.Label] + PADDING)//2, center_x - (PATCH_SIZES[row.Label] + PADDING)//2:center_x + (PATCH_SIZES[row.Label] + PADDING)//2, :]\n",
        "plt.imshow(img/255.0)"
      ],
      "metadata": {
        "id": "2RQ_bWyP-jT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "4Il9I4T3pa0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not PATCHES:\n",
        "  !rm -r /content/drive/MyDrive/Patches256_v4\n",
        "  !mkdir /content/drive/MyDrive/Patches256_v4\n",
        "  for index, row in tqdm(df.iterrows(), total=df.shape[0], position=0, leave=True):\n",
        "    try:\n",
        "      img = cv2.imread(IMAGE_DIR + row.fileName.lower()[:-2] + '.png')\n",
        "      center_x = int((row.bbox[0] + row.bbox[2]) / 2)\n",
        "      center_y = int((row.bbox[1] + row.bbox[3]) / 2)\n",
        "      img = img[center_y - (PATCH_SIZES[row.Label] + PADDING)//2:center_y + (PATCH_SIZES[row.Label] + PADDING)//2, center_x - (PATCH_SIZES[row.Label] + PADDING)//2:center_x + (PATCH_SIZES[row.Label] + PADDING)//2, :]\n",
        "      cv2.imwrite('/content/drive/MyDrive/Patches256_v4/' + row.fileName.lower() + '.png', img)\n",
        "      del img\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "h9-sdtW8NwU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "dgXcey7gpiM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_DIR = '/content/drive/MyDrive/Patches256_v4/'\n",
        "fileNames = [x.split('/')[-1].lower()[:-4] for x in glob(PATCH_DIR + '*.png')]\n",
        "df.fileName = df['fileName'].apply(lambda x: x.lower())\n",
        "new_df = df[df.fileName.isin(fileNames)]\n",
        "df = new_df"
      ],
      "metadata": {
        "id": "g46PGP_YAnXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "id": "s_mB7NyF9Ues"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxNS0hqm02pl"
      },
      "outputs": [],
      "source": [
        "class embeddingDataset(Dataset):\n",
        "  def __init__(self, df, transforms=None):\n",
        "    self.images = []\n",
        "    self.transforms = transforms\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0], position=0, leave=True):\n",
        "      img = cv2.imread(PATCH_DIR + row.fileName.lower() + '.png') / 255.0\n",
        "      self.images.append(img)\n",
        "      del img\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.images[idx]\n",
        "    img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"RGB\")\n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img/255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.PILToTensor())\n",
        "    if train:\n",
        "      transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "      transforms.append(T.RandomVerticalFlip(0.5))\n",
        "      transforms.append(T.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(1, 1)))\n",
        "    else:\n",
        "      transforms.append(T.RandomResizedCrop(256, scale=(0.8, 1.0), ratio=(1, 1)))\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "aw7ToEiGAk_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(glob(PATCH_DIR + '*.png')))"
      ],
      "metadata": {
        "id": "w1AeDzCFhecc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEJp0QBvjCH5"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, \n",
        "                                          random_state=42, shuffle=True)\n",
        "\n",
        "train_transforms = get_transform(True)\n",
        "val_transforms = get_transform(False)\n",
        "train_ae_dataset, val_ae_dataset = embeddingDataset(train_df, transforms=train_transforms), embeddingDataset(val_df, transforms=val_transforms)\n",
        "train_ae_dataloader = DataLoader(train_ae_dataset, batch_size=4, shuffle=True,\n",
        "                                 pin_memory=True)\n",
        "val_ae_dataloader = DataLoader(val_ae_dataset, batch_size=4, shuffle=True,\n",
        "                                 pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AadKwES--dRI"
      },
      "outputs": [],
      "source": [
        "train_ae_dataset[0].detach().numpy().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnjVJ0kk8Mop"
      },
      "outputs": [],
      "source": [
        "idx=0\n",
        "plt.imshow(np.transpose(train_ae_dataset[idx].numpy(), (1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXJuAUXzjy39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgy93WRZFZHK"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqeENnBVBvvo"
      },
      "outputs": [],
      "source": [
        "class EncoderModule(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.module = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,\n",
        "                  (3,3), stride=2, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.module(X)\n",
        "\n",
        "class DecoderModule(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.module = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                  (3,3), stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU()\n",
        "    )\n",
        "  def forward(self, X):\n",
        "    return self.module(X)\n",
        "\n",
        "class VAEBase(nn.Module):\n",
        "  def __init__(self, in_channels, latent_dim, hidden_dims):\n",
        "    super().__init__()\n",
        "\n",
        "    self.latent_dims = latent_dim\n",
        "    self.hidden_dims = hidden_dims\n",
        "\n",
        "    encoder_modules = []\n",
        "    for hidden in self.hidden_dims:\n",
        "      encoder_modules.append(EncoderModule(in_channels, hidden))\n",
        "\n",
        "      in_channels = hidden\n",
        "\n",
        "    self.encoder = nn.Sequential(*encoder_modules)\n",
        "\n",
        "    self.fc_mu = nn.Linear(hidden_dims[-1]*64, latent_dim)\n",
        "    self.fc_var = nn.Linear(hidden_dims[-1]*64, latent_dim)\n",
        "\n",
        "    decoder_modules = []\n",
        "\n",
        "    self.start_decode = nn.Linear(latent_dim, hidden_dims[-1]*64)\n",
        "\n",
        "    for i in reversed(range(len(hidden_dims)-1)):\n",
        "      decoder_modules.append(DecoderModule(hidden_dims[i+1],\n",
        "                                           hidden_dims[i]))\n",
        "    decoder_modules.append(nn.Sequential(\n",
        "        nn.ConvTranspose2d(hidden_dims[0], hidden_dims[0], kernel_size=3,\n",
        "                           stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(hidden_dims[0]),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(hidden_dims[0], 3, 3, padding=1),\n",
        "        nn.Tanh()\n",
        "    ))\n",
        "\n",
        "    self.decoder = nn.Sequential(*decoder_modules)\n",
        "\n",
        "  def forward(self, X):\n",
        "    encoded = self.encoder(X)\n",
        "    encoded = torch.flatten(encoded, start_dim=1)\n",
        "    mu = self.fc_mu(encoded)\n",
        "    var = self.fc_var(encoded)\n",
        "    \n",
        "    std = torch.exp(0.5 * var)\n",
        "    eps = torch.randn_like(std)\n",
        "\n",
        "    z = eps * std + mu\n",
        "    z = self.start_decode(z)\n",
        "    z = z.view(-1, 512, 8, 8)\n",
        "    decoded = self.decoder(z)\n",
        "\n",
        "    return decoded, X, mu, var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-4uFNAXCngX"
      },
      "outputs": [],
      "source": [
        "VAE = VAEBase(3, 12288, [32,64,128,256,512]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMgGwyRby5Zd"
      },
      "outputs": [],
      "source": [
        "def read_data(X):\n",
        "  return X.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(decoded, input, mu, var):\n",
        "  decoded = decoded\n",
        "  input = input\n",
        "  mu = mu\n",
        "  var = var\n",
        "  kld_weight = 0.5\n",
        "  recons_loss =F.mse_loss(decoded, input)\n",
        "\n",
        "\n",
        "  kld_loss = torch.mean(-0.5 * torch.sum(1 + var - mu ** 2 - var.exp(), dim = 1), dim = 0)\n",
        "  # print(recons_loss)\n",
        "  # print(kld_loss)\n",
        "  loss = recons_loss + kld_weight * kld_loss\n",
        "  return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n"
      ],
      "metadata": {
        "id": "PIqrZyogDCnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEs_-0akhSZM"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, epochs=300, lr=0.0001):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5),int(epochs*0.75)], gamma=0.1)\n",
        "  # loss_fn = nn.CrossEntropyLoss()\n",
        "  loss_fn = loss_function\n",
        "  training_data = pd.DataFrame(columns=['Epoch', 'Train Loss', 'Val Loss'])\n",
        "  for e in range(epochs):\n",
        "    model.train()\n",
        "    tbar = tqdm(train_loader, position=0, leave=True)\n",
        "    \n",
        "    start = time.time()\n",
        "    train_loss_temp = []\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch, (X) in enumerate(tbar):\n",
        "      img = read_data(X)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      decoded, input, mu, var = model(img)\n",
        "      loss = loss_fn(decoded, input, mu, var)\n",
        "      losses = loss['loss']\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss_temp.append(losses.detach().cpu().numpy().ravel())\n",
        "\n",
        "      tbar.set_description('Epoch: %i, Loss: %f' % (e+1, np.round(np.mean(train_loss_temp),4)))\n",
        "\n",
        "    model.eval()\n",
        "    vbar = tqdm(val_loader, position=0, leave=True)\n",
        "    val_loss_temp = []\n",
        "    with torch.no_grad():\n",
        "      for batch, (X) in enumerate(vbar):\n",
        "        img = read_data(X)\n",
        "\n",
        "        decoded, input, mu, var = model(img)\n",
        "        loss = loss_fn(decoded, input, mu, var)\n",
        "        loss = loss['loss']\n",
        "        val_loss_temp.append(loss.detach().cpu().numpy().ravel())\n",
        "\n",
        "        vbar.set_description('Epoch: %i, Val Loss: %f' % (e+1, np.round(np.mean(val_loss_temp),4)))\n",
        "    \n",
        "    end = time.time()\n",
        "    training_data.at[e, 'Epoch'] = e+1\n",
        "    training_data.at[e, 'Train Loss'] = np.round(np.mean(train_loss_temp),4)\n",
        "    training_data.at[e, 'Val Loss'] = np.round(np.mean(val_loss_temp),4)\n",
        "    scheduler.step()\n",
        "\n",
        "  return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3KdmgYl0X7H"
      },
      "outputs": [],
      "source": [
        "train(VAE, train_ae_dataloader, val_ae_dataloader, 100, 0.00005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMpi1hxoDIVP"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.transpose(VAE(val_ae_dataset[5].unsqueeze(0).cuda())[0].detach().cpu().numpy().squeeze(), (1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_93UJgMQCx"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.transpose(VAE(val_ae_dataset[0]).detach().numpy(), (1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c05DoSLcMf4o"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.transpose(val_ae_dataset[0], (1,2,0)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOoCL0S1oegGVpnvF6wC0Ph",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjdolan/HighResolutionSemanticClassification/blob/main/BiFPN_RemoteSensingObjectDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdPdmMX8jIXT"
      },
      "source": [
        "R-CNN with BiFPN Notebook\n",
        "Author: Connor Dolan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54Uqv_15qF2O"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IAZdbptm_0u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urljoin\n",
        "from shapely.geometry import Polygon\n",
        "import numpy as np\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import zipfile\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import auth\n",
        "import os\n",
        "import shutil\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import rasterio\n",
        "from ast import literal_eval\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbNLEoZ0pVwl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ATML_Dataset_Largest.csv')\n",
        "df.head(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDke8Mr1JCiL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZDRPuD5ra6V"
      },
      "outputs": [],
      "source": [
        "df['bbox'] = df['bbox'].apply(lambda x: literal_eval(x))\n",
        "df['Class'] = df['Class'].apply(lambda x: literal_eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nukMxYZYqA7p"
      },
      "outputs": [],
      "source": [
        "def correct_bbox(fileName, bbox):\n",
        "  new_bbox = []\n",
        "  try:\n",
        "    with rasterio.open('/content/drive/MyDrive/ATMLData/atml_bucket/' + fileName.lower() + '.tif') as img:\n",
        "      for box in bbox:\n",
        "        new_box = []\n",
        "        y_old = img.shape[0]\n",
        "        x_old = img.shape[1]\n",
        "\n",
        "        for i in range(4):\n",
        "          old = None\n",
        "          if i % 2 == 0:\n",
        "            old = x_old\n",
        "          else:\n",
        "            old = y_old\n",
        "          new_val = int((float(box[i]) / float(old)) * 1500)\n",
        "          if new_val < 0:\n",
        "            new_val = 0\n",
        "          elif new_val > 1500:\n",
        "            new_val = 1500\n",
        "          new_box.append(new_val)\n",
        "\n",
        "\n",
        "        new_bbox.append(new_box)\n",
        "  except:\n",
        "    pass\n",
        "  return new_bbox\n",
        "\n",
        "print(correct_bbox(df.at[4, 'fileName'], df.at[8, 'bbox']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMq4P9tUy24n"
      },
      "outputs": [],
      "source": [
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG2mJSqSwOPF"
      },
      "outputs": [],
      "source": [
        "df['bbox'] = df[['fileName', 'bbox']].progress_apply(lambda x: correct_bbox(x.fileName, x.bbox), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idquGfHDy8F6"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/ATML_Dataset_1500.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfv1q0CypOgs"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ATML_Dataset_1500.csv')\n",
        "df['bbox'] = df['bbox'].apply(lambda x: literal_eval(x))\n",
        "df['Class'] = df['Class'].apply(lambda x: literal_eval(x))\n",
        "encodings = {'airport':0, 'stadium':1, 'power_plant':2}\n",
        "\n",
        "df['Label'] = df['Class'].apply(lambda x: [encodings[y] for y in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jv6_rv48pX4"
      },
      "outputs": [],
      "source": [
        "new_df = pd.DataFrame(columns=df.columns)\n",
        "idx = 0\n",
        "for index, row in tqdm(df.iterrows(), position=0, leave=True):\n",
        "  if len(row.bbox) > 0:\n",
        "    new_df.at[idx, 'fileName'] = row.fileName\n",
        "    new_df.at[idx, 'bbox'] = row.bbox\n",
        "    new_df.at[idx, 'Class'] = row.Class\n",
        "    new_df.at[idx, 'Label'] = row.Label\n",
        "    idx += 1\n",
        "df = new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUM-4FgisALd"
      },
      "outputs": [],
      "source": [
        "IMG_DIR = '/content/drive/MyDrive/NAIP_Lower_Res_1500_v3/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "id": "TpK8SzSBRcic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKoxjJZUsXQT"
      },
      "outputs": [],
      "source": [
        "from d2l import torch as d2l\n",
        "\n",
        "def bbox_to_rect(bbox, color):\n",
        "    \"\"\"Convert bounding box to matplotlib format.\"\"\"\n",
        "    # Convert the bounding box (upper-left x, upper-left y, lower-right x,\n",
        "    # lower-right y) format to the matplotlib format: ((upper-left x,\n",
        "    # upper-left y), width, height)\n",
        "    return d2l.plt.Rectangle(\n",
        "        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\n",
        "        fill=False, edgecolor=color, linewidth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVqUElmksH56"
      },
      "outputs": [],
      "source": [
        "idx = 60\n",
        "\n",
        "img = cv2.imread(IMG_DIR + df.at[idx, 'fileName'].lower() + '.png')[905:946,502:527]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Display the image\n",
        "ax.imshow(img)\n",
        "ax.add_patch(bbox_to_rect(df.at[idx, 'bbox'][0], 'blue'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x86TBoCVCQX4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X_0BrStYdOf"
      },
      "outputs": [],
      "source": [
        "def overlap(rect1,rect2):\n",
        "  try:\n",
        "    p1 = Polygon([[rect1[0], rect1[1]], [rect1[2],rect1[1]],\n",
        "                  [rect1[0], rect1[3]], [rect1[2], rect1[3]]])\n",
        "    p2 = Polygon([[rect2[0], rect2[1]], [rect2[2],rect2[1]],\n",
        "                  [rect2[0], rect2[3]], [rect2[2], rect2[3]]])\n",
        "    return(p1.intersects(p2))\n",
        "  except:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwAIvC1mucPq"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5-H067DGFs5"
      },
      "outputs": [],
      "source": [
        "class Compose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoNavrr2G8n3"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.15.1\n",
        "\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBLmCu_xHJ8Y"
      },
      "outputs": [],
      "source": [
        "import transforms as T\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    transforms.append(T.PILToTensor())\n",
        "    if train:\n",
        "      transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFu3_fg-D6aB"
      },
      "outputs": [],
      "source": [
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg15_MxCl-8E"
      },
      "outputs": [],
      "source": [
        "class RemoteDataset(Dataset):\n",
        "  def __init__(self, fileNames, bboxes, classes, transformations=None, validation=False):\n",
        "    self.images = []\n",
        "    self.targets = []\n",
        "    self.bboxes = bboxes\n",
        "    self.classes = classes\n",
        "    self.validation = validation\n",
        "    self.transforms = transformations\n",
        "    if not validation:\n",
        "      for f in tqdm(fileNames, position=0, leave=True):\n",
        "        try:\n",
        "          img = cv2.imread(IMG_DIR + f.lower() + '.png') / 255.0\n",
        "          self.images.append(img)\n",
        "        except:\n",
        "          continue\n",
        "    else:\n",
        "      for i,f in tqdm(enumerate(fileNames), position=0, leave=True):\n",
        "        try:\n",
        "          img = cv2.imread(IMG_DIR + f.lower() + '.png') / 255.0\n",
        "          bboxes = self.bboxes[i]\n",
        "          bbox = bboxes[0]\n",
        "          label = self.classes[i]\n",
        "\n",
        "          final_boxes = []\n",
        "          final_classes = []\n",
        "\n",
        "          if bbox[0] < (1500-bbox[2]):\n",
        "            start_x = random.randint(0, min(bbox[0], 860))\n",
        "            while start_x + 640 < bbox[2]:\n",
        "              start_x += 100\n",
        "            end_x = start_x + 640\n",
        "            x1 = bbox[0] - start_x\n",
        "            x2 = bbox[2] - start_x\n",
        "          else:\n",
        "            end_x = random.randint(max(bbox[2], 640), 1500)\n",
        "            while end_x - 640 > bbox[0]:\n",
        "              end_x -= 100\n",
        "            start_x = end_x - 640\n",
        "            x1 = bbox[0] - start_x\n",
        "            x2 = bbox[2] - start_x\n",
        "          if bbox[1] < (1500-bbox[3]):\n",
        "            start_y = random.randint(0, min(bbox[1], 860))\n",
        "            while start_y + 640 < bbox[3]:\n",
        "              start_y += 100\n",
        "            end_y = start_y + 640\n",
        "            y1 = bbox[1] - start_y\n",
        "            y2 = bbox[3] - start_y\n",
        "          else:\n",
        "            end_y = random.randint(max(bbox[3], 640), 1500)\n",
        "            while end_y - 640 > bbox[1]:\n",
        "              end_y -= 100\n",
        "            start_y = end_y - 640\n",
        "            y1 = bbox[1] - start_y\n",
        "            y2 = bbox[3] - start_y\n",
        "\n",
        "          img = img[start_y:end_y,start_x:end_x,:]\n",
        "\n",
        "          for i, b in enumerate(bboxes):\n",
        "            new_b = [0.0,0.0,0.0,0.0]\n",
        "            new_b[0] = max(b[0] - start_x, 0)\n",
        "            new_b[1] = min(b[1] - start_y, 640)\n",
        "            new_b[2] = max(b[2] - start_x, 0)\n",
        "            new_b[3] = min(b[3] - start_y, 640)\n",
        "            if overlap(b, [start_x, start_y, end_x, end_y]) and new_b[0] < new_b[2] and new_b[1] < new_b[3]:\n",
        "              final_boxes.append([p for p in new_b])\n",
        "              final_classes.append(label[i]+1)\n",
        "          if len(final_boxes) == 0:\n",
        "            final_boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            final_classes.append(0)\n",
        "          else:\n",
        "            # bounding box to tensor\n",
        "            final_boxes = torch.as_tensor(final_boxes, dtype=torch.float32)\n",
        "          # area of the bounding boxes\n",
        "          area = (final_boxes[:, 3] - final_boxes[:, 1]) * (final_boxes[:, 2] - final_boxes[:, 0])\n",
        "          # no crowd instances\n",
        "          iscrowd = torch.zeros((final_boxes.shape[0],), dtype=torch.int64)\n",
        "          # labels to tensor\n",
        "          final_classes = torch.as_tensor(final_classes, dtype=torch.int64)\n",
        "          # prepare the final `target` dictionary\n",
        "          target = {}\n",
        "          target[\"boxes\"] = final_boxes\n",
        "          target[\"labels\"] = final_classes\n",
        "          target[\"area\"] = area\n",
        "          target[\"iscrowd\"] = iscrowd\n",
        "          image_id = torch.tensor([idx])\n",
        "          target[\"image_id\"] = image_id\n",
        "          img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"RGB\")\n",
        "          if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "          target[\"bbox\"] = target[\"boxes\"]\n",
        "          target[\"cls\"] = target[\"labels\"]\n",
        "          self.images.append(img)\n",
        "          self.targets.append(target)\n",
        "        except:\n",
        "          continue\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.bboxes)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img = self.images[idx]\n",
        "    if not self.validation:\n",
        "      bboxes = self.bboxes[idx]\n",
        "      bbox = bboxes[0]\n",
        "      label = self.classes[idx]\n",
        "\n",
        "      final_boxes = []\n",
        "      final_classes = []\n",
        "\n",
        "      if bbox[0] < (1500-bbox[2]):\n",
        "        start_x = random.randint(0, min(bbox[0], 860))\n",
        "        while start_x + 640 < bbox[2]:\n",
        "          start_x += 100\n",
        "        end_x = start_x + 640\n",
        "        x1 = bbox[0] - start_x\n",
        "        x2 = bbox[2] - start_x\n",
        "      else:\n",
        "        end_x = random.randint(max(bbox[2], 640), 1500)\n",
        "        while end_x - 640 > bbox[0]:\n",
        "          end_x -= 100\n",
        "        start_x = end_x - 640\n",
        "        x1 = bbox[0] - start_x\n",
        "        x2 = bbox[2] - start_x\n",
        "      if bbox[1] < (1500-bbox[3]):\n",
        "        start_y = random.randint(0, min(bbox[1], 860))\n",
        "        while start_y + 640 < bbox[3]:\n",
        "          start_y += 100\n",
        "        end_y = start_y + 640\n",
        "        y1 = bbox[1] - start_y\n",
        "        y2 = bbox[3] - start_y\n",
        "      else:\n",
        "        end_y = random.randint(max(bbox[3], 640), 1500)\n",
        "        while end_y - 640 > bbox[1]:\n",
        "          end_y -= 100\n",
        "        start_y = end_y - 640\n",
        "        y1 = bbox[1] - start_y\n",
        "        y2 = bbox[3] - start_y\n",
        "\n",
        "      img = img[start_y:end_y,start_x:end_x,:]\n",
        "\n",
        "      for i, b in enumerate(bboxes):\n",
        "        new_b = [0.0,0.0,0.0,0.0]\n",
        "        new_b[0] = max(b[0] - start_x, 0)\n",
        "        new_b[1] = max(b[1] - start_y, 0)\n",
        "        new_b[2] = min(b[2] - start_x, 640)\n",
        "        new_b[3] = min(b[3] - start_y, 640)\n",
        "        if overlap(b, [start_x, start_y, end_x, end_y]) and new_b[0] < new_b[2] and new_b[1] < new_b[3]:\n",
        "          final_boxes.append([p for p in new_b])\n",
        "          final_classes.append(label[i]+1)\n",
        "      if len(final_boxes) == 0:\n",
        "        final_boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "        final_classes.append(0)\n",
        "      else:\n",
        "        # bounding box to tensor\n",
        "        final_boxes = torch.as_tensor(final_boxes, dtype=torch.float32)\n",
        "      # area of the bounding boxes\n",
        "      area = (final_boxes[:, 3] - final_boxes[:, 1]) * (final_boxes[:, 2] - final_boxes[:, 0])\n",
        "      # no crowd instances\n",
        "      iscrowd = torch.zeros((final_boxes.shape[0],), dtype=torch.int64)\n",
        "      # labels to tensor\n",
        "      final_classes = torch.as_tensor(final_classes, dtype=torch.int64)\n",
        "      # prepare the final `target` dictionary\n",
        "      target = {}\n",
        "      target[\"boxes\"] = final_boxes\n",
        "      target[\"labels\"] = final_classes\n",
        "      target[\"area\"] = area\n",
        "      target[\"iscrowd\"] = iscrowd\n",
        "      image_id = torch.tensor([idx])\n",
        "      target[\"image_id\"] = image_id\n",
        "      img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"RGB\")\n",
        "      if self.transforms is not None:\n",
        "        img, target = self.transforms(img, target)\n",
        "      target[\"bbox\"] = target[\"boxes\"]\n",
        "      target[\"cls\"] = target[\"labels\"]\n",
        "    else:\n",
        "      target = self.targets[idx]\n",
        "\n",
        "    return img/255.0, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYMxSEiRjoMG"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA_RmkJMRI9T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df.iloc[0:10], test_size=0.2, shuffle=True, random_state=42)\n",
        "train_dataset = RemoteDataset(train_df['fileName'].tolist(), train_df['bbox'].tolist(), train_df['Label'].tolist(), get_transform(True), validation=False)\n",
        "val_dataset = RemoteDataset(val_df['fileName'].tolist(), val_df['bbox'].tolist(), val_df['Label'].tolist(), get_transform(False), validation=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWI9Y4lqHo4h"
      },
      "outputs": [],
      "source": [
        "idx = 2\n",
        "sample = train_dataset[idx]\n",
        "img = sample[0]\n",
        "print(img.shape)\n",
        "targets = sample[1]\n",
        "bboxes = targets['boxes']\n",
        "print(targets['labels'])\n",
        "print(bboxes)\n",
        "img = np.transpose(img.detach().numpy(),(1,2,0))#[int(bbox[1]):int(bbox[3]),int(bbox[0]):int(bbox[2])]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Display the image\n",
        "ax.imshow(img)\n",
        "for box in bboxes.detach().numpy():\n",
        "  if box[0] >= 0:\n",
        "    ax.add_patch(bbox_to_rect(box, 'blue'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D-R8SHHEUdw"
      },
      "outputs": [],
      "source": [
        "train_dataset[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaAB_-4eDQLV"
      },
      "outputs": [],
      "source": [
        "def iou(y_true, y_pred):\n",
        "  intsersection_x1 = np.maximum(y_true[0], y_pred[0])\n",
        "  intsersection_x2 = np.minimum(y_true[2], y_pred[2])\n",
        "  intsersection_y1 = np.maximum(y_true[1], y_pred[1])\n",
        "  intsersection_y2 = np.minimum(y_true[3], y_pred[3])\n",
        "\n",
        "  x_diff = np.maximum(intsersection_x2 - intsersection_x1 + 1, np.array(0.))\n",
        "  y_diff = np.maximum(intsersection_y2 - intsersection_y1 + 1, np.array(0.))\n",
        "\n",
        "  intersection = x_diff * y_diff\n",
        "\n",
        "  true_x = y_true[2] - y_true[0] + 1\n",
        "  true_y = y_true[3] - y_true[1] + 1\n",
        "\n",
        "  pred_x = y_pred[2] - y_pred[0] + 1\n",
        "  pred_y = y_pred[3] - y_pred[1] + 1\n",
        "\n",
        "  union = true_x * true_y + pred_x * pred_y - intersection\n",
        "\n",
        "  return intersection / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y6sxLtrLgrG"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9bEkQTIDVBp"
      },
      "outputs": [],
      "source": [
        "def multi_iou(y_true, y_pred):\n",
        "  canvas = np.zeros(640*640).reshape([640,640])\n",
        "  true_canvas = canvas.copy()\n",
        "  for t in y_true:\n",
        "    true_canvas = cv2.rectangle(true_canvas,\n",
        "                                (int(t[0]),int(t[1])),\n",
        "                                (int(t[2]),int(t[3])),\n",
        "                                1,\n",
        "                                -1)\n",
        "  pred_canvas = canvas.copy()\n",
        "  for p in y_pred:\n",
        "    pred_canvas = cv2.rectangle(pred_canvas,\n",
        "                                (int(p[0]),int(p[1])),\n",
        "                                (int(p[2]),int(p[3])),\n",
        "                                2,\n",
        "                                -1)\n",
        "  actual = np.matrix(true_canvas)\n",
        "  predictions = np.matrix(pred_canvas)\n",
        "  combined = np.squeeze(np.asarray(actual + predictions))\n",
        "\n",
        "  unique, counts = np.unique(combined, return_counts=True)\n",
        "  mapping = defaultdict(lambda: 0, zip(unique, counts))\n",
        "\n",
        "  TN = mapping[0]\n",
        "  FN = mapping[1]\n",
        "  FP = mapping[2]\n",
        "  TP = mapping[3]\n",
        "\n",
        "  added = 0\n",
        "\n",
        "  if len(y_pred) == 0:\n",
        "    return -1,-1,-1\n",
        "\n",
        "  if (TP + FN) == 0 or (TP + FP) == 0:\n",
        "    added += 1\n",
        "  iou = float(TP) / float((FN + FP + TP + added))\n",
        "  precision = float(TP) / float((TP + FP + added))\n",
        "  recall = float(TP) / float((TP + FN + added))\n",
        "\n",
        "  return iou, precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GARvAsYYH8Ch"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tYpeej8v9MZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivGP3NbtGwLs"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.nn import Identity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/rwightman/efficientdet-pytorch.git\n",
        "cd efficientdet-pytorch\n",
        "\n",
        "cp effdet/efficientdet.py ../\n",
        "cp effdet/anchors.py ../\n",
        "cp effdet/__init__.py ../\n",
        "cp -r effdet/config/ ../"
      ],
      "metadata": {
        "id": "DrMeEvArXsrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "9Ejn0ndEgTtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rwightman/efficientdet-pytorch.git"
      ],
      "metadata": {
        "id": "QVpXbBkre7mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install effdet"
      ],
      "metadata": {
        "id": "XhTsQKL8jHEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FnBYWN7fp2ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "BzapGbxaqJqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from effdet.config import get_fpn_config, get_efficientdet_config\n",
        "from effdet.efficientdet import BiFpn, get_feature_info, create_model, HeadNet\n",
        "\n",
        "\n",
        "class BiFPN_Backbone(nn.Module):\n",
        "  def __init__(self, backbone, bifpn, layers, config):\n",
        "    super().__init__()\n",
        "    self.backbone = backbone\n",
        "    self.bifpn = bifpn\n",
        "    self.layers = layers\n",
        "    self.config = config\n",
        "    self.class_net = HeadNet(self.config, num_outputs=4)\n",
        "    self.box_net = HeadNet(self.config, num_outputs=4)\n",
        "  def forward(self, X):\n",
        "    x = self.backbone(X)\n",
        "    x = self.bifpn(x)\n",
        "    \n",
        "    cls = self.class_net(x)\n",
        "    box = self.box_net(x)\n",
        "    return cls, box\n",
        "\n",
        "# class BiFPN_Backbone(nn.Module):\n",
        "#   def __init__(self, backbone, bifpn, layers):\n",
        "#     super().__init__()\n",
        "#     self.backbone = backbone\n",
        "#     self.bifpn = bifpn\n",
        "#     self.layers = layers\n",
        "\n",
        "#   def forward(self, X):\n",
        "#     x = self.backbone(X)\n",
        "#     x = self.bifpn(x)\n",
        "#     d = {}\n",
        "#     for i in range(len(self.layers)):\n",
        "#       d[i] = x[i]\n",
        "#       print(x[i].shape)\n",
        "\n",
        "#     return d\n",
        "\n",
        "def create_model_bifpn(num_classes):\n",
        "    \n",
        "    # load Faster RCNN pre-trained model\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, trainable_backbone_layers=5)\n",
        "    config = get_efficientdet_config('resdet50')\n",
        "    config['fpn_channels'] = 256\n",
        "    config['num_levels'] = 5\n",
        "    config['max_level'] = 7\n",
        "    config['min_level'] = 3\n",
        "    config['num_classes'] = 3\n",
        "    backbone = create_model(\n",
        "            'resnet50',\n",
        "            features_only=True,\n",
        "            out_indices=config.backbone_indices or (2,3,4),\n",
        "            pretrained=False,\n",
        "            **config.backbone_args\n",
        "        )\n",
        "    bifpn_config = get_fpn_config('bifpn_sum')\n",
        "    # bifpn_config['num_levels'] = 3\n",
        "    # bifpn_config['norm_layer'] = None\n",
        "    # bifpn_config['norm_kwargs'] = None\n",
        "    # bifpn_config['act_type'] = 'swish'\n",
        "    config['fpn_config'] = bifpn_config\n",
        "    bifpn = BiFpn(config, get_feature_info(backbone))\n",
        "    # get the number of input features \n",
        "    #model.backbone.fpn = bifpn\n",
        "    model = BiFPN_Backbone(backbone, bifpn, (2,3,4), config)\n",
        "    #in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # define a new head for the detector with required number of classes\n",
        "    #model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
        "    return model\n",
        "\n",
        "model = create_model_bifpn(4).cuda()"
      ],
      "metadata": {
        "id": "9EdXF5tCx8ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from effdet.efficientdet import EfficientDet\n",
        "from effdet.bench import DetBenchTrain\n",
        "config = get_efficientdet_config('resdet50')\n",
        "config['fpn_channels'] = 88\n",
        "config['num_classes'] = 3\n",
        "backbone = create_model(\n",
        "        'resnet50',\n",
        "        features_only=True,\n",
        "        out_indices=(0,1,2,3,4),\n",
        "        pretrained=False,\n",
        "        **config.backbone_args\n",
        "    )\n",
        "bifpn_config = get_fpn_config('bifpn_sum')\n",
        "# bifpn_config['num_levels'] = 3\n",
        "# bifpn_config['norm_layer'] = None\n",
        "# bifpn_config['norm_kwargs'] = None\n",
        "# bifpn_config['act_type'] = 'swish'\n",
        "config['fpn_config'] = bifpn_config\n",
        "\n",
        "model = EfficientDet(config, True, False).cpu()"
      ],
      "metadata": {
        "id": "iIzsMd7Xpp9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "QioaS9X_Klnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][1]['bbox'] = train_dataset[0][1]['bbox'].contiguous()"
      ],
      "metadata": {
        "id": "wVpSSmhPDYjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][1]"
      ],
      "metadata": {
        "id": "tRDS6zoo8BeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config)"
      ],
      "metadata": {
        "id": "uhqlAivzsETZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.unsqueeze(0).shape"
      ],
      "metadata": {
        "id": "0172pPFbtTW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DetBenchTrain(model).cuda()"
      ],
      "metadata": {
        "id": "P2iHdq9gGvGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config.keys())"
      ],
      "metadata": {
        "id": "GfMUD07bOCTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "sample = train_dataset[4]\n",
        "img = sample[0]\n",
        "target = sample[1]\n",
        "target['bbox'].cuda()\n",
        "target['cls'].cuda()\n",
        "\n",
        "print(target)\n",
        "model(img.unsqueeze(0).cuda(), target=target)"
      ],
      "metadata": {
        "id": "thk8fmYcrzEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26PsT5rlG1jj"
      },
      "outputs": [],
      "source": [
        "def read_data(X):\n",
        "  images = list(image.cuda() for image in X[0])\n",
        "  targets = [{k: v.cuda() for k, v in t.items()} for t in X[1]]\n",
        "  return images, targets\n",
        "# For Training\n",
        "model.train()\n",
        "X = next(iter(train_loader))\n",
        "images, targets = read_data(X)\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "#print(output)\n",
        "model.eval()\n",
        "train_preds = model(images)\n",
        "for i in range(len(train_preds)):\n",
        "  num_true_boxes = len(targets[i]['boxes'])\n",
        "\n",
        "  multi_iou(targets[i]['boxes'][0:num_true_boxes], \n",
        "            train_preds[i]['boxes'][0:num_true_boxes])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl-TwwauJi13"
      },
      "outputs": [],
      "source": [
        "for i in range(len(train_preds)):\n",
        "  num_true_boxes = len(targets[i]['boxes'])\n",
        "\n",
        "  multi_iou(targets[i]['boxes'][0:num_true_boxes], \n",
        "            train_preds[i]['boxes'][0:num_true_boxes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO-dBNlqCthf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wswjQJbUMa59"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "model.cuda()\n",
        "images = [t.cuda() for t in images]\n",
        "model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux4nZ6jFCIlL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMeHHBXREYA7"
      },
      "outputs": [],
      "source": [
        "model.to('cuda')\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EciK3iMwK6yN"
      },
      "outputs": [],
      "source": [
        "# model = torchvision.models.resnet50()\n",
        "# req_layers = list(model.children())[:8]\n",
        "# backbone = nn.Sequential(*req_layers)\n",
        "# out = backbone(torch.unsqueeze(train_dataset[0][0], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1Nf--HI3alK"
      },
      "outputs": [],
      "source": [
        "# model = torchvision.models.resnet50()\n",
        "# for p in backbone.named_parameters():\n",
        "#   print(p[1].requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHllUC3Gr1hr"
      },
      "outputs": [],
      "source": [
        "# out_c, out_h, out_w = out.size(dim=1), out.size(dim=2), out.size(dim=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckfwc5lkg-En"
      },
      "outputs": [],
      "source": [
        "from torchvision import ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWl9F2UFkF-y"
      },
      "outputs": [],
      "source": [
        "!mv /content/drive/MyDrive/utils.py /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gensCCVXqTQy"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28YX-xJcAyJD"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet50()\n",
        "req_layers = list(model.children())[:8]\n",
        "backbone = nn.Sequential(*req_layers)\n",
        "out = backbone(torch.unsqueeze(train_dataset[0][0], 0))\n",
        "out_c, out_h, out_w = out.size(dim=1), out.size(dim=2), out.size(dim=3)\n",
        "dummy_img = torch.zeros((1, 3, 600, 600)).float()\n",
        "print(out_c)\n",
        "print(out_h)\n",
        "print(out_w)\n",
        "out_map = backbone(dummy_img)\n",
        "print(out_map.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3cY3dYIMOna"
      },
      "outputs": [],
      "source": [
        "def read_data(X):\n",
        "  images = list(image.cuda() for image in X[0])\n",
        "  targets = [{k: v.cuda() for k, v in t.items()} for t in X[1]]\n",
        "  return images, targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import evaluate"
      ],
      "metadata": {
        "id": "TBxfvN1Dj6lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ08JO46vMPu"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, epochs=300, lr=0.1):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(epochs*0.5),int(epochs*0.75)], gamma=0.1)\n",
        "  # loss_fn = nn.CrossEntropyLoss()\n",
        "  classLossFunc = nn.CrossEntropyLoss()\n",
        "  bboxLossFunc = nn.MSELoss()\n",
        "  training_data = pd.DataFrame(columns=['Epoch', 'Train Loss', 'Train IOU', 'Train Precision'\n",
        "                                        'Train Recall', 'Val Loss', 'Val IOU', 'Val Precision', 'Val Recall'])\n",
        "  for e in range(epochs):\n",
        "    model.train()\n",
        "    tbar = tqdm(train_loader, position=0, leave=True)\n",
        "    \n",
        "    start = time.time()\n",
        "    train_loss_temp = []\n",
        "    train_iou_temp = []\n",
        "    train_precision_temp = []\n",
        "    train_recall_temp = []\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch, (X) in enumerate(tbar):\n",
        "      model.train()\n",
        "      img, y_true = read_data(X)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss = model(img, y_true)\n",
        "      losses = sum(loss for loss in loss.values())\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history = losses.item()\n",
        "\n",
        "      train_loss_temp.append(loss_history)\n",
        "\n",
        "\n",
        "      model.eval()\n",
        "      train_preds = model(img)\n",
        "      iou = 0.0\n",
        "      recall = 0.0\n",
        "      precision = 0.0\n",
        "      total_count = 0\n",
        "      for i in range(len(train_preds)):\n",
        "        num_true_boxes = len(y_true[i]['boxes'])\n",
        "        if num_true_boxes > 0:\n",
        "          temp_iou, temp_precision, temp_recall = multi_iou(y_true[i]['boxes'][0:num_true_boxes], \n",
        "                    train_preds[i]['boxes'][0:num_true_boxes])\n",
        "          \n",
        "          if temp_iou >= 0:\n",
        "            iou += temp_iou\n",
        "            recall += temp_recall\n",
        "            precision += temp_precision\n",
        "            total_count += 1\n",
        "\n",
        "      if total_count > 0:\n",
        "        iou /= total_count\n",
        "        recall /= total_count\n",
        "        precision /= total_count\n",
        "\n",
        "      train_iou_temp.append(iou)\n",
        "      train_precision_temp.append(precision)\n",
        "      train_recall_temp.append(recall)\n",
        "\n",
        "      tbar.set_description('Epoch: %i, Loss: %f, IoU: %f, Precision: %f, Recall: %f' % (e+1, np.round(np.mean(train_loss_temp),4),\n",
        "                                                                                        np.round(np.mean(train_iou_temp),4),\n",
        "                                                                                        np.round(np.mean(train_precision_temp),4),\n",
        "                                                                                        np.round(np.mean(train_recall_temp),4)))\n",
        "\n",
        "    model.eval()\n",
        "    vbar = tqdm(val_loader, position=0, leave=True)\n",
        "    val_loss_temp = []\n",
        "    val_iou_temp = []\n",
        "    val_precision_temp = []\n",
        "    val_recall_temp = []\n",
        "    with torch.no_grad():\n",
        "      for batch, (X) in enumerate(vbar):\n",
        "        img, y_true = read_data(X)\n",
        "\n",
        "        y_preds = model(img, y_true)\n",
        "\n",
        "        iou = 0.0\n",
        "        recall = 0.0\n",
        "        precision = 0.0\n",
        "        total_count = 0\n",
        "        for i in range(len(y_preds)):\n",
        "          num_true_boxes = len(y_true[i]['boxes'])\n",
        "          if num_true_boxes > 0:\n",
        "            temp_iou, temp_precision, temp_recall = multi_iou(y_true[i]['boxes'][0:num_true_boxes], \n",
        "                      y_preds[i]['boxes'][0:num_true_boxes])\n",
        "            \n",
        "            if temp_iou >= 0:\n",
        "              iou += temp_iou\n",
        "              recall += temp_recall\n",
        "              precision += temp_precision\n",
        "              total_count += 1\n",
        "\n",
        "        if total_count > 0:\n",
        "          iou /= total_count\n",
        "          recall /= total_count\n",
        "          precision /= total_count\n",
        "          \n",
        "\n",
        "        val_iou_temp.append(iou)\n",
        "        val_precision_temp.append(precision)\n",
        "        val_recall_temp.append(recall)\n",
        "\n",
        "        #losses = sum(loss for loss in loss.values())\n",
        "\n",
        "        #loss_history = losses.item()\n",
        "\n",
        "        #val_loss_temp.append(loss_history)\n",
        "\n",
        "        vbar.set_description('Epoch: %i, Val IoU: %f, Val Precision: %f, Val Recall: %f' % (e+1,\n",
        "                                                                                            np.round(np.mean(val_iou_temp),4),\n",
        "                                                                                            np.round(np.mean(val_precision_temp),4),\n",
        "                                                                                            np.round(np.mean(val_recall_temp),4)))\n",
        "    evaluate(model, val_loader, 'cuda')\n",
        "    end = time.time()\n",
        "    training_data.at[e, 'Epoch'] = e+1\n",
        "    training_data.at[e, 'Train Loss'] = np.round(np.mean(train_loss_temp),4)\n",
        "    training_data.at[e, 'Train IOU'] = np.round(np.mean(train_iou_temp),4)\n",
        "    training_data.at[e, 'Train Precision'] = np.round(np.mean(train_precision_temp),4)\n",
        "    training_data.at[e, 'Train Recall'] = np.round(np.mean(train_recall_temp),4)\n",
        "    training_data.at[e, 'Val Loss'] = np.round(np.mean(val_loss_temp),4)\n",
        "    training_data.at[e, 'Val IOU'] = np.round(np.mean(val_iou_temp),4)\n",
        "    training_data.at[e, 'Val Precision'] = np.round(np.mean(val_precision_temp),4)\n",
        "    training_data.at[e, 'Val Recall'] = np.round(np.mean(val_recall_temp),4)\n",
        "    scheduler.step()\n",
        "\n",
        "  return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyUNFEoBP4Je"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNQJGP93Wv6R"
      },
      "outputs": [],
      "source": [
        "training_data = train(model, train_loader, val_loader, epochs=300, lr=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6IQDNDYIbeq"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/ATMLModels\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/ATMLModels/RCNN_FPN.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqJ8QSn-CtKX"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/ATMLResults\n",
        "training_data.to_csv('/content/drive/MyDrive/ATMLResults/RCNN_FPN_RESULTS.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP2z8ojBzbLrfFybjZh5Poz",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}